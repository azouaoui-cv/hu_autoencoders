{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementation of method CNNAEU\n",
    "Published in\n",
    "\n",
    "B. Palsson, M. O. Ulfarsson and J. R. Sveinsson, \"Convolutional Autoencoder for Spectralâ€“Spatial Hyperspectral Unmixing,\" in IEEE Transactions on Geoscience and Remote Sensing, vol. 59, no. 1, pp. 535-549, Jan. 2021, doi: 10.1109/TGRS.2020.2992743."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "from scipy import io as sio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorflow.keras import Model, Sequential, layers, optimizers, activations\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method load_HSI\n",
    "Loads the HSI and reference endmembers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_HSI(path):\n",
    "    try:\n",
    "        data = sio.loadmat(path)\n",
    "    except NotImplementedError:\n",
    "        data = hdf.File(path, 'r')\n",
    "\n",
    "    Y = np.asarray(data['Y'], dtype=np.float32)\n",
    "    GT = np.asarray(data['GT'], dtype=np.float32)\n",
    "    if Y.shape[0] < Y.shape[1]:\n",
    "        Y = Y.transpose()\n",
    "    Y = Y / np.max(Y.flatten())\n",
    "    n_bands = Y.shape[1]\n",
    "    n_rows = data['lines'].item()\n",
    "    n_cols = data['cols'].item()\n",
    "    Y = np.reshape(Y, (n_cols, n_rows, n_bands))\n",
    "    return Y, GT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method training_input_fn\n",
    "Extracts patches for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_input_fn(hsi, patch_size, patch_number, batch_size):\n",
    "    patches = extract_patches_2d(hsi, (patch_size, patch_size), max_patches=patch_number)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class SumToOne\n",
    "Enforces the ASC. Regularizations on the abundance maps go in here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumToOne(tf.keras.layers.Layer):\n",
    "    def __init__(self, params, **kwargs):\n",
    "        super(SumToOne, self).__init__(**kwargs)\n",
    "        self.num_outputs = params['num_endmembers']\n",
    "        self.params = params\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 2\n",
    "        input_dim = input_shape[-1]\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = tf.nn.softmax(self.params['scale'] * x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Encoder\n",
    "Extends the Model class. Encodes input patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, params):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.params = params\n",
    "        self.hidden_layer_one = tf.keras.layers.Conv2D(filters=self.params['e_filters'],\n",
    "                                                       kernel_size=self.params['e_size'],\n",
    "                                                       activation=self.params['activation'], strides=1, padding='same',\n",
    "                                                       kernel_initializer=params['initializer'], use_bias=False)\n",
    "        self.hidden_layer_two = tf.keras.layers.Conv2D(filters=self.params['num_endmembers'], kernel_size=1,\n",
    "                                                       activation=self.params['activation'], strides=1, padding='same',\n",
    "                                                       kernel_initializer=self.params['initializer'], use_bias=False)\n",
    "        self.asc_layer = SumToOne(params=self.params, name='abundances')\n",
    "\n",
    "    def call(self, input_patch):\n",
    "        code = self.hidden_layer_one(input_patch)\n",
    "        code = tf.keras.layers.BatchNormalization()(code)\n",
    "        code = tf.keras.layers.SpatialDropout2D(0.2)(code)\n",
    "        code = self.hidden_layer_two(code)\n",
    "        code = tf.keras.layers.BatchNormalization()(code)\n",
    "        code = tf.keras.layers.SpatialDropout2D(0.2)(code)\n",
    "        code = self.asc_layer(code)\n",
    "        return code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Decoder\n",
    "Extends the Layer class. Decodes abundance patches and reconstructs the inputs to the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, params):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_layer = tf.keras.layers.Conv2D(filters=params['d_filters'], kernel_size=params['d_size'],\n",
    "                                                   activation='linear',\n",
    "                                                   kernel_constraint=tf.keras.constraints.non_neg(),\n",
    "                                                   name='endmembers', strides=1, padding='same',\n",
    "                                                   kernel_regularizer=None,\n",
    "                                                   kernel_initializer=params['initializer'], use_bias=False)\n",
    "\n",
    "    def call(self, code):\n",
    "        recon = self.output_layer(code)\n",
    "        return recon\n",
    "\n",
    "    def getEndmembers(self):\n",
    "        return self.output_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Autoencoder\n",
    "Extends the Model class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, params):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(params)\n",
    "        self.decoder = Decoder(params)\n",
    "        self.params = params\n",
    "\n",
    "    def call(self, patch):\n",
    "        abunds = self.encoder(patch)\n",
    "        # tf.summary.histogram('abunds', abunds, step=1)\n",
    "        #         abunds = tf.keras.layers.SpatialDropout2D(0.08)(abunds)\n",
    "        output = self.decoder(abunds)\n",
    "        return output\n",
    "\n",
    "    def getEndmembers(self):\n",
    "        endmembers = self.decoder.getEndmembers()[0]\n",
    "        if endmembers.shape[1] > 1:\n",
    "            endmembers = np.squeeze(endmembers).mean(axis=0).mean(axis=0)\n",
    "        else:\n",
    "            endmembers = np.squeeze(endmembers)\n",
    "        return endmembers\n",
    "\n",
    "    def getAbundances(self, hsi):\n",
    "        return np.squeeze(self.encoder.predict(np.expand_dims(hsi, 0)))\n",
    "\n",
    "    def train(self, patches, callback):\n",
    "        self.plotWhileTraining = callback\n",
    "        self.fit(patches, patches, epochs=self.params['epochs'], batch_size=self.params['batch_size'],\n",
    "                 callbacks=[self.plotWhileTraining], verbose=0)\n",
    "\n",
    "    def saveResults(self, fname):\n",
    "        endmembers = self.getEndmembers()\n",
    "        abundances = self.getAbundances(params['data'])\n",
    "        sads = self.plotWhileTraining.sads\n",
    "        sio.savemat(fname, {'M': endmembers, 'A': abundances, 'sads': sads})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAD and Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAD(y_true, y_pred):\n",
    "    y_true = tf.math.l2_normalize(y_true, axis=-1)\n",
    "    y_pred = tf.math.l2_normalize(y_pred, axis=-1)\n",
    "    A = (y_true * y_pred)\n",
    "    sad = tf.math.acos(A)\n",
    "    return sad\n",
    "\n",
    "def numpy_SAD(y_true, y_pred):\n",
    "    return np.arccos(y_pred.dot(y_true) / (np.linalg.norm(y_true) * np.linalg.norm(y_pred)))\n",
    "\n",
    "\n",
    "def loss(model, original):\n",
    "    reconstruction_error = SAD(model(original), original)\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various functions for training and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss, model, opt, original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(model, original) + sum(model.losses), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)\n",
    "\n",
    "\n",
    "def order_endmembers(endmembers, endmembersGT):\n",
    "    num_endmembers = endmembers.shape[0]\n",
    "    dict = {}\n",
    "    sad_mat = np.ones((num_endmembers, num_endmembers))\n",
    "    for i in range(num_endmembers):\n",
    "        endmembers[i, :] = endmembers[i, :] / endmembers[i, :].max()\n",
    "        endmembersGT[i, :] = endmembersGT[i, :] / endmembersGT[i, :].max()\n",
    "    for i in range(num_endmembers):\n",
    "        for j in range(num_endmembers):\n",
    "            sad_mat[i, j] = numpy_SAD(endmembers[i, :], endmembersGT[j, :])\n",
    "    rows = 0\n",
    "    while rows < num_endmembers:\n",
    "        minimum = sad_mat.min()\n",
    "        index_arr = np.where(sad_mat == minimum)\n",
    "        if len(index_arr) < 2:\n",
    "            break\n",
    "        index = (index_arr[0][0], index_arr[1][0])\n",
    "        if index[0] in dict.keys():\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "        elif index[1] in dict.values():\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "        else:\n",
    "            dict[index[0]] = index[1]\n",
    "            sad_mat[index[0], index[1]] = 100\n",
    "            rows += 1\n",
    "    ASAM = 0\n",
    "    num = 0\n",
    "    for i in range(num_endmembers):\n",
    "        if np.var(endmembersGT[dict[i]]) > 0:\n",
    "            ASAM = ASAM + numpy_SAD(endmembers[i, :], endmembersGT[dict[i]])\n",
    "            num += 1\n",
    "\n",
    "    return dict, ASAM / float(num)\n",
    "\n",
    "\n",
    "def plotEndmembers(endmembers):\n",
    "    endmembers = endmembers / endmembers.max()\n",
    "    fig = plt.figure(1)\n",
    "    for i in range(num_endmembers):\n",
    "        ax = plt.subplot(2, 2, i + 1)\n",
    "        plt.plot(endmembers[i, :], 'r', linewidth=1.0)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plotEndmembersAndGT(endmembers, endmembersGT):\n",
    "    num_endmembers = endmembers.shape[0]\n",
    "    n = num_endmembers // 2  # how many digits we will display\n",
    "    if num_endmembers % 2 != 0: n = n + 1\n",
    "    dict, sad = order_endmembers(endmembers, endmembersGT)\n",
    "\n",
    "    fig = plt.figure(num=1, figsize=(8, 8))\n",
    "    plt.clf()\n",
    "    title = \"aSAM score for all endmembers: \" + format(sad, '.3f') + \" radians\"\n",
    "    st = plt.suptitle(title)\n",
    "    for i in range(num_endmembers):\n",
    "        endmembers[i, :] = endmembers[i, :] / endmembers[i, :].max()\n",
    "        endmembersGT[i, :] = endmembersGT[i, :] / endmembersGT[i, :].max()\n",
    "\n",
    "    for i in range(num_endmembers):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.plot(endmembers[i, :], 'r', linewidth=1.0)\n",
    "        plt.plot(endmembersGT[dict[i], :], 'k', linewidth=1.0)\n",
    "        ax.set_title(\"SAD: \" + str(i) + \" :\" + format(numpy_SAD(endmembers[i, :], endmembersGT[dict[i], :]), '.4f'))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    st.set_y(0.95)\n",
    "    fig.subplots_adjust(top=0.88)\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "def plotAbundancesSimple(abundances):\n",
    "    abundances = np.transpose(abundances, axes=[1, 0, 2])\n",
    "    num_endmembers = abundances.shape[2]\n",
    "    n = num_endmembers // 2\n",
    "    if num_endmembers % 2 != 0: n = n + 1\n",
    "    fig = plt.figure(2, figsize=[8, 8])\n",
    "    for i in range(num_endmembers):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(position='bottom', size='5%', pad=0.05)\n",
    "        im = ax.imshow(abundances[:, :, i], cmap='viridis')\n",
    "        plt.colorbar(im, cax=cax, orientation='horizontal')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        im.set_clim([0, 1])\n",
    "    plt.tight_layout()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "class PlotWhileTraining(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, plot_every_n, hsi, gt):\n",
    "        super(PlotWhileTraining, self).__init__()\n",
    "        self.plot_every_n = plot_every_n\n",
    "        num_endmembers = gt.shape[0]\n",
    "        self.num_endmembers = num_endmembers\n",
    "        self.input = hsi\n",
    "        self.endmembersGT = gt\n",
    "        self.sads = None\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_loss = []\n",
    "        self.sads = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs.get('SAD'))\n",
    "        self.num_epochs = epoch\n",
    "        print('*',end='')\n",
    "        if self.plot_every_n == 0 or epoch % self.plot_every_n != 0:\n",
    "            return\n",
    "        plotEndmembersAndGT(self.endmembersGT, endmembers)\n",
    "        abundances = self.model.getAbundances(self.input)\n",
    "        plotAbundancesSimple(abundances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters and load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparmameter settings\n",
    "n_bands = 162\n",
    "num_endmembers = 4\n",
    "patch_size = 40\n",
    "num_patches = 250\n",
    "batch_size = 15\n",
    "learning_rate = 0.003\n",
    "epochs = 320\n",
    "\n",
    "scale = 3 #scaling for softmax\n",
    "l2 = 0\n",
    "l1 = 0e-8\n",
    "tv = 0e-8\n",
    "\n",
    "activation = tf.keras.layers.LeakyReLU(0.02)\n",
    "initializer = tf.keras.initializers.RandomNormal(0.0, 0.3)\n",
    "regularizer = tf.keras.regularizers.l2(l2)\n",
    "\n",
    "opt = tf.optimizers.RMSprop(learning_rate=learning_rate, decay=0.0)\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "#Dictonary of aliases for datasets. The first string is the key and second is value (name of matfile without .mat suffix)\n",
    "#Useful when looping over datasets\n",
    "datasetnames = {\n",
    "    \"Urban\": \"Urban4\",\n",
    "}\n",
    "dataset = \"Urban\"\n",
    "data,GT = load_HSI(\n",
    "    \"./Datasets/\" + datasetnames[dataset] + \".mat\"\n",
    ")\n",
    "\n",
    "#e_filters is the number of featuremaps in the first hidden layer\n",
    "#d_size is the decoder's filter size\n",
    "#e_size is the size of the hidden layer's filter\n",
    "\n",
    "params = {'e_filters': 48, 'e_size': 3, 'd_filters': n_bands, 'd_size': 13, 'activation': activation,\n",
    "          'num_endmembers': num_endmembers, 'scale': scale, 'regularizer': regularizer,\n",
    "          'initializer': initializer, 'l1': l1, 'tv': tv, 'patch_size': patch_size,\n",
    "          'batch_size': batch_size, 'num_patches': num_patches, 'data': data, 'epochs': epochs}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 25\n",
    "results_folder = './Results'\n",
    "method_name = 'CNNAEU'\n",
    "\n",
    "plot_every_n = 0 #Plot endmembers and abundance maps every x epochs. Set to 0 when running experiments. \n",
    "for dataset in ['Urban']:\n",
    "    save_folder = results_folder+'/'+method_name+'/'+dataset\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    dataset_name = 'synthetic'\n",
    "\n",
    "    data,GT = load_HSI(\n",
    "        \"./Datasets/\" + datasetnames[dataset] + \".mat\"\n",
    "    )\n",
    "    for i in range(num_runs):\n",
    "        print('Run number: '+str(i+1))\n",
    "        save_name = dataset_name+'_run'+str(i)+'.mat'\n",
    "        save_path = save_folder+'/'+save_name\n",
    "        patches = training_input_fn(data, patch_size, num_patches, batch_size)\n",
    "        params = {'e_filters': 48, 'e_size': 3, 'd_filters': n_bands, 'd_size': 13, 'activation': activation,\n",
    "              'num_endmembers': num_endmembers, 'scale': scale, 'regularizer': regularizer,\n",
    "              'initializer': initializer, 'patch_size': patch_size,\n",
    "              'batch_size': batch_size, 'num_patches': num_patches, 'data': data, 'epochs': epochs}\n",
    "        autoencoder = Autoencoder(params)\n",
    "\n",
    "        autoencoder.compile(opt, loss=SAD)\n",
    "        autoencoder.train(callback=PlotWhileTraining(plot_every_n, data, GT), patches=patches)\n",
    "        endmembers = autoencoder.getEndmembers()\n",
    "        abundances = autoencoder.getAbundances(data)\n",
    "        plotAbundancesSimple(abundances)\n",
    "        plotEndmembersAndGT(endmembers,hsi.gt)\n",
    "        autoencoder.saveResults(save_path+'_run' + str(i+1) + '.mat')\n",
    "        del autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
