{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of \n",
    "# NEURAL NETWORK HYPERSPECTRAL UNMIXING WITH SPECTRAL INFORMATION DIVERGENCE OBJECTIVE*\n",
    "\n",
    "F. Palsson, J. Sigurdsson, J. R. Sveinsson and M. O. Ulfarsson, \"Neural network hyperspectral unmixing with spectral information divergence objective,\" 2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2017, pp. 755-758, doi: 10.1109/IGARSS.2017.8127062."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers, constraints, layers, activations, regularizers\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from unmixing import HSI, plotEndmembers,SAD\n",
    "from unmixing import plotEndmembersAndGT, plotAbundancesSimple, load_HSI, PlotWhileTraining\n",
    "from scipy import io as sio\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import warnings\n",
    "import matplotlib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class SparseReLU\n",
    "Performs dynamic thresholding of abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseReLU(tf.keras.layers.Layer):\n",
    "    def __init__(self,params):\n",
    "        self.params=params\n",
    "        super(SparseReLU, self).__init__()\n",
    "        self.alpha = self.add_weight(shape=(self.params['num_endmembers'],),initializer=tf.keras.initializers.Zeros(),\n",
    "        trainable=True, constraint=tf.keras.constraints.non_neg())\n",
    "    def build(self, input_shape):\n",
    "        self.alpha = self.add_weight(shape=input_shape[1:],initializer=tf.keras.initializers.Zeros(),\n",
    "        trainable=True, constraint=tf.keras.constraints.non_neg())\n",
    "        super(SparseReLU, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        return tf.keras.backend.relu(x - self.alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class SumToOne\n",
    "Performs abundance normalization to enforce ASC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumToOne(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SumToOne, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x *= K.cast(x >= K.epsilon(), K.floatx())\n",
    "        x = K.relu(x)\n",
    "        x = x/(K.sum(x, axis=-1, keepdims=True)+K.epsilon())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SID Loss function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SID(y_true, y_pred):\n",
    "    y_true = K.switch(K.min(y_true) < 0, y_true - K.min(y_true) + K.epsilon(), y_true + K.epsilon())\n",
    "    y_pred = K.switch(K.min(y_pred) < 0, y_pred - K.min(y_pred) + K.epsilon(), y_pred + K.epsilon())\n",
    "\n",
    "    p_n = y_true / K.sum(y_true, axis=1, keepdims=True)\n",
    "    q_n = y_pred / K.sum(y_pred, axis=1, keepdims=True)\n",
    "    return K.sum(p_n * K.log(p_n / q_n)) + K.sum(q_n * K.log(q_n / p_n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Autoencoder\n",
    "Wrapper class for the autoencoder model and associcated utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "    def __init__(self, params):\n",
    "        self.data = params[\"data\"].array()\n",
    "        self.params = params\n",
    "        self.decoder = layers.Dense(\n",
    "            units=self.params[\"n_bands\"],\n",
    "            kernel_regularizer=None,\n",
    "            activation=\"linear\",\n",
    "            name=\"output\",\n",
    "            use_bias=False,\n",
    "            kernel_constraint=constraints.non_neg()\n",
    "        )\n",
    "        self.hidden = layers.Dense(\n",
    "            units=self.params[\"num_endmembers\"],\n",
    "            activation='linear',\n",
    "            name='hidden1',\n",
    "            use_bias=False\n",
    "        )\n",
    "        self.sparseReLU = SparseReLU(params)\n",
    "        self.asc_layer = SumToOne(name='abundances')\n",
    "        self.model = self.create_model()\n",
    "        self.model.compile(optimizer=self.params[\"optimizer\"], loss=self.params[\"loss\"])\n",
    "        \n",
    "    def create_model(self):\n",
    "        input_features = layers.Input(shape=(self.params[\"n_bands\"],))\n",
    "        code = self.hidden(input_features)\n",
    "        code = layers.BatchNormalization()(code)\n",
    "        code = self.sparseReLU(code)\n",
    "        abunds = self.asc_layer(code)\n",
    "        output = self.decoder(abunds)\n",
    "\n",
    "        return tf.keras.Model(inputs=input_features, outputs=output)\n",
    "        \n",
    "    \n",
    "    def fit(self,data,n):\n",
    "        plot_callback = PlotWhileTraining(n,self.params['data'])\n",
    "        return self.model.fit(\n",
    "            x=data,\n",
    "            y=data,\n",
    "            batch_size=self.params[\"batch_size\"],\n",
    "            epochs=self.params[\"epochs\"],\n",
    "            callbacks=[plot_callback]\n",
    "        )\n",
    "\n",
    "    def get_endmembers(self):\n",
    "        return self.model.layers[len(self.model.layers) - 1].get_weights()[0]\n",
    "\n",
    "    def get_abundances(self):\n",
    "        intermediate_layer_model = tf.keras.Model(\n",
    "            inputs=self.model.input, outputs=self.model.get_layer(\"abundances\").output\n",
    "        )\n",
    "        abundances = intermediate_layer_model.predict(self.data)\n",
    "        abundances = np.reshape(abundances,[self.params['data'].cols,self.params['data'].rows,self.params['num_endmembers']])\n",
    "        \n",
    "        return abundances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictonary of aliases for datasets. The first string is the key and second is value (name of matfile without .mat suffix)\n",
    "#Useful when looping over datasets\n",
    "datasetnames = {\"Urban\": \"Urban4\"\n",
    "}\n",
    "\n",
    "dataset = \"Urban\"\n",
    "\n",
    "hsi = load_HSI(\n",
    "    \"./Datasets/\" + datasetnames[dataset] + \".mat\"\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "num_endmembers = 4\n",
    "num_spectra = 2000\n",
    "batch_size = 5\n",
    "learning_rate = 0.001\n",
    "epochs = 40\n",
    "loss = SID\n",
    "opt = tf.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "data = hsi.array()\n",
    "\n",
    "# Hyperparameter dictionary\n",
    "params = {\n",
    "    \"num_endmembers\": num_endmembers,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"num_spectra\": num_spectra,\n",
    "    \"data\": hsi,\n",
    "    \"epochs\": epochs,\n",
    "    \"n_bands\": hsi.bands,\n",
    "    \"GT\": hsi.gt,\n",
    "    \"lr\": learning_rate,\n",
    "    \"optimizer\": opt,\n",
    "    \"loss\": loss,\n",
    "}\n",
    "\n",
    "plot_every = 0 #Plot endmembers and abundance maps every x epochs. Set to 0 when running experiments. \n",
    "\n",
    "training_data = data[\n",
    "    np.random.randint(0, data.shape[0], num_spectra), :\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(params)\n",
    "autoencoder.fit(training_data,plot_every)\n",
    "endmembers = autoencoder.get_endmembers()\n",
    "abundances = autoencoder.get_abundances()\n",
    "plotEndmembersAndGT(endmembers, hsi.gt)\n",
    "plotAbundancesSimple(abundances,'abund.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 25\n",
    "plot_every = 0 #Plot endmembers and abundance maps every x epochs. Set to 0 when running experiments. \n",
    "\n",
    "results_folder = './Results'\n",
    "\n",
    "method_name = 'SIDAEU'\n",
    "\n",
    "for dataset in ['Urban']:\n",
    "    save_folder = results_folder+'/'+method_name+'/'+dataset\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    hsi = load_HSI(\n",
    "        \"./Datasets/\" + datasetnames[dataset] + \".mat\"\n",
    "    )\n",
    "    data=hsi.array()\n",
    "    batch_size = 256\n",
    "    params['data']=hsi\n",
    "    params['n_bands']=hsi.bands\n",
    "\n",
    "    for run in range(1,num_runs+1):\n",
    "        training_data = data[np.random.randint(0, data.shape[0], num_spectra), :]\n",
    "        save_name = dataset+'_run'+str(run)+'.mat'\n",
    "        save_path = save_folder+'/'+save_name\n",
    "        autoencoder = Autoencoder(params)\n",
    "        autoencoder.fit(training_data,plot_every)\n",
    "        endmembers = autoencoder.get_endmembers()\n",
    "        abundances = autoencoder.get_abundances()\n",
    "        plotEndmembersAndGT(endmembers, hsi.gt)\n",
    "        plotAbundancesSimple(abundances,'abund.png')\n",
    "        sio.savemat(save_path,{'M':endmembers,'A':abundances})\n",
    "        del autoencoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
